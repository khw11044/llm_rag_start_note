{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 모델 직렬화(Serialization) - 저장 및 불러오기\n",
    "\n",
    "직렬화를 이용한 프롬프트 저장과 로딩\n",
    "\n",
    "\n",
    "프롬프트를 수시로 변경해야 하는 경우도 있고, 국제화된 애플리케이션을 개발하기 위해서는 같은 프롬프트도 다국어로 개발해야 할 경우가 있다. 이런 경우 애플리케이션 코드내에서 하드코딩된 프롬프트보다. 프롬프트 템플릿을 별도의 파일로 저장하여, 애플리케이션에서 로드하여 사용할 수 있다. 이를 Serialization (직렬화)라고 한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain 은 직렬화(Serialization) 체계를 공유합니다.\n",
    "\n",
    "is_lc_serializable 클래스 메서드로 실행하여 LangChain 클래스가 직렬화 가능한지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.messages import stream_response\n",
    "from langchain.llms.loading import load_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 FewShotPromptTemplate의 모델 직렬화 및 저장하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"instruction\": \"당신은 회의록 작성 전문가 입니다. 주어진 정보를 바탕으로 회의록을 작성해 주세요\",\n",
    "        \"input\": \"2023년 12월 25일, XYZ 회사의 마케팅 전략 회의가 오후 3시에 시작되었다. 회의에는 마케팅 팀장인 김수진, 디지털 마케팅 담당자인 박지민, 소셜 미디어 관리자인 이준호가 참석했다. 회의의 주요 목적은 2024년 상반기 마케팅 전략을 수립하고, 새로운 소셜 미디어 캠페인에 대한 아이디어를 논의하는 것이었다. 팀장인 김수진은 최근 시장 동향에 대한 간략한 개요를 제공했으며, 이어서 각 팀원이 자신의 분야에서의 전략적 아이디어를 발표했다.\",\n",
    "        \"answer\": \"\"\"\n",
    "회의록: XYZ 회사 마케팅 전략 회의\n",
    "일시: 2023년 12월 25일\n",
    "장소: XYZ 회사 회의실\n",
    "참석자: 김수진 (마케팅 팀장), 박지민 (디지털 마케팅 담당자), 이준호 (소셜 미디어 관리자)\n",
    "\n",
    "1. 개회\n",
    "   - 회의는 김수진 팀장의 개회사로 시작됨.\n",
    "   - 회의의 목적은 2024년 상반기 마케팅 전략 수립 및 새로운 소셜 미디어 캠페인 아이디어 논의.\n",
    "\n",
    "2. 시장 동향 개요 (김수진)\n",
    "   - 김수진 팀장은 최근 시장 동향에 대한 분석을 제시.\n",
    "   - 소비자 행동 변화와 경쟁사 전략에 대한 통찰 공유.\n",
    "\n",
    "3. 디지털 마케팅 전략 (박지민)\n",
    "   - 박지민은 디지털 마케팅 전략에 대해 발표.\n",
    "   - 온라인 광고와 SEO 최적화 방안에 중점을 둠.\n",
    "\n",
    "4. 소셜 미디어 캠페인 (이준호)\n",
    "   - 이준호는 새로운 소셜 미디어 캠페인에 대한 아이디어를 제안.\n",
    "   - 인플루언서 마케팅과 콘텐츠 전략에 대한 계획을 설명함.\n",
    "\n",
    "5. 종합 논의\n",
    "   - 팀원들 간의 아이디어 공유 및 토론.\n",
    "   - 각 전략에 대한 예산 및 자원 배분에 대해 논의.\n",
    "\n",
    "6. 마무리\n",
    "   - 다음 회의 날짜 및 시간 확정.\n",
    "   - 회의록 정리 및 배포는 박지민 담당.\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"당신은 요약 전문가 입니다. 다음 주어진 정보를 바탕으로 내용을 요약해 주세요\",\n",
    "        \"input\": \"이 문서는 '지속 가능한 도시 개발을 위한 전략'에 대한 20페이지 분량의 보고서입니다. 보고서는 지속 가능한 도시 개발의 중요성, 현재 도시화의 문제점, 그리고 도시 개발을 지속 가능하게 만들기 위한 다양한 전략을 포괄적으로 다루고 있습니다. 이 보고서는 또한 성공적인 지속 가능한 도시 개발 사례를 여러 국가에서 소개하고, 이러한 사례들을 통해 얻은 교훈을 요약하고 있습니다.\",\n",
    "        \"answer\": \"\"\"\n",
    "문서 요약: 지속 가능한 도시 개발을 위한 전략 보고서\n",
    "\n",
    "- 중요성: 지속 가능한 도시 개발이 필수적인 이유와 그에 따른 사회적, 경제적, 환경적 이익을 강조.\n",
    "- 현 문제점: 현재의 도시화 과정에서 발생하는 주요 문제점들, 예를 들어 환경 오염, 자원 고갈, 불평등 증가 등을 분석.\n",
    "- 전략: 지속 가능한 도시 개발을 달성하기 위한 다양한 전략 제시. 이에는 친환경 건축, 대중교통 개선, 에너지 효율성 증대, 지역사회 참여 강화 등이 포함됨.\n",
    "- 사례 연구: 전 세계 여러 도시의 성공적인 지속 가능한 개발 사례를 소개. 예를 들어, 덴마크의 코펜하겐, 일본의 요코하마 등의 사례를 통해 실현 가능한 전략들을 설명.\n",
    "- 교훈: 이러한 사례들에서 얻은 주요 교훈을 요약. 강조된 교훈에는 다각적 접근의 중요성, 지역사회와의 협력, 장기적 계획의 필요성 등이 포함됨.\n",
    "\n",
    "이 보고서는 지속 가능한 도시 개발이 어떻게 현실적이고 효과적인 형태로 이루어질 수 있는지에 대한 심도 있는 분석을 제공합니다.\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"당신은 문장 교정 전문가 입니다. 다음 주어진 문장을 교정해 주세요\",\n",
    "        \"input\": \"우리 회사는 새로운 마케팅 전략을 도입하려고 한다. 이를 통해 고객과의 소통이 더 효과적이 될 것이다.\",\n",
    "        \"answer\": \"본 회사는 새로운 마케팅 전략을 도입함으로써, 고객과의 소통을 보다 효과적으로 개선할 수 있을 것으로 기대된다.\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.example_selectors import (\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma = Chroma(\"fewshot_chat\", OpenAIEmbeddings())\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{instruction}:\\n{input}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 여기에는 선택 가능한 예시 목록이 있습니다.\n",
    "    examples,\n",
    "    # 여기에는 의미적 유사성을 측정하는 데 사용되는 임베딩을 생성하는 임베딩 클래스가 있습니다.\n",
    "    OpenAIEmbeddings(),\n",
    "    # 여기에는 임베딩을 저장하고 유사성 검색을 수행하는 데 사용되는 VectorStore 클래스가 있습니다.\n",
    "    chroma,\n",
    "    # 이것은 생성할 예시의 수입니다.\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': '\\n회의록: XYZ 회사 마케팅 전략 회의\\n일시: 2023년 12월 25일\\n장소: XYZ 회사 회의실\\n참석자: 김수진 (마케팅 팀장), 박지민 (디지털 마케팅 담당자), 이준호 (소셜 미디어 관리자)\\n\\n1. 개회\\n   - 회의는 김수진 팀장의 개회사로 시작됨.\\n   - 회의의 목적은 2024년 상반기 마케팅 전략 수립 및 새로운 소셜 미디어 캠페인 아이디어 논의.\\n\\n2. 시장 동향 개요 (김수진)\\n   - 김수진 팀장은 최근 시장 동향에 대한 분석을 제시.\\n   - 소비자 행동 변화와 경쟁사 전략에 대한 통찰 공유.\\n\\n3. 디지털 마케팅 전략 (박지민)\\n   - 박지민은 디지털 마케팅 전략에 대해 발표.\\n   - 온라인 광고와 SEO 최적화 방안에 중점을 둠.\\n\\n4. 소셜 미디어 캠페인 (이준호)\\n   - 이준호는 새로운 소셜 미디어 캠페인에 대한 아이디어를 제안.\\n   - 인플루언서 마케팅과 콘텐츠 전략에 대한 계획을 설명함.\\n\\n5. 종합 논의\\n   - 팀원들 간의 아이디어 공유 및 토론.\\n   - 각 전략에 대한 예산 및 자원 배분에 대해 논의.\\n\\n6. 마무리\\n   - 다음 회의 날짜 및 시간 확정.\\n   - 회의록 정리 및 배포는 박지민 담당.\\n',\n",
       "  'input': '2023년 12월 25일, XYZ 회사의 마케팅 전략 회의가 오후 3시에 시작되었다. 회의에는 마케팅 팀장인 김수진, 디지털 마케팅 담당자인 박지민, 소셜 미디어 관리자인 이준호가 참석했다. 회의의 주요 목적은 2024년 상반기 마케팅 전략을 수립하고, 새로운 소셜 미디어 캠페인에 대한 아이디어를 논의하는 것이었다. 팀장인 김수진은 최근 시장 동향에 대한 간략한 개요를 제공했으며, 이어서 각 팀원이 자신의 분야에서의 전략적 아이디어를 발표했다.',\n",
       "  'instruction': '당신은 회의록 작성 전문가 입니다. 주어진 정보를 바탕으로 회의록을 작성해 주세요'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = {\n",
    "    \"instruction\": \"회의록을 작성해 주세요\",\n",
    "    \"input\": \"2023년 12월 26일, ABC 기술 회사의 제품 개발 팀은 새로운 모바일 애플리케이션 프로젝트에 대한 주간 진행 상황 회의를 가졌다. /이 회의에는 프로젝트 매니저인 최현수, 주요 개발자인 황지연, UI/UX 디자이너인 김태영이 참석했다. 회의의 주요 목적은 프로젝트의 현재 진행 상황을 검토하고, 다가오는 마일스톤에 대한 계획을 수립하는 것이었다. 각 팀원은 자신의 작업 영역에 대한 업데이트를 제공했고, 팀은 다음 주까지의 목표를 설정했다.\",\n",
    "}\n",
    "\n",
    "example_selector.select_examples(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{instruction}\\n{input}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회의록: ABC 기술 회사 제품 개발 팀 주간 진행 상황 회의\n",
      "일시: 2023년 12월 26일\n",
      "장소: ABC 기술 회사 회의실\n",
      "참석자: 최현수 (프로젝트 매니저), 황지연 (주요 개발자), 김태영 (UI/UX 디자이너)\n",
      "\n",
      "1. 개회\n",
      "   - 회의는 최현수 프로젝트 매니저의 개회사로 시작됨.\n",
      "   - 회의의 목적은 새로운 모바일 애플리케이션 프로젝트의 주간 진행 상황 검토 및 다가오는 마일스톤 계획 수립.\n",
      "\n",
      "2. 현재 진행 상황 업데이트\n",
      "   - 각 참석자가 자신의 작업 영역에 대한 업데이트를 제공.\n",
      "   - 황지연 주요 개발자는 기술적 측면에서의 진행 상황을 공유.\n",
      "   - 김태영 UI/UX 디자이너는 사용자 경험 및 디자인 측면에서의 업데이트를 제공.\n",
      "\n",
      "3. 다가오는 마일스톤 계획 수립\n",
      "   - 팀은 다음 주까지의 목표를 설정하고 이를 달성하기 위한 계획을 논의.\n",
      "   - 최현수 프로젝트 매니저는 일정 및 리소스 할당에 대한 계획을 제시.\n",
      "\n",
      "4. 토론 및 의견 공유\n",
      "   - 팀원들 간의 의견 교환 및 토론.\n",
      "   - 프로젝트 진행에 대한 개선점 및 추가적인 사항에 대한 토의.\n",
      "\n",
      "5. 마무리\n",
      "   - 다음 회의 일정 및 주요 안건 확정.\n",
      "   - 회의록은 김태영 UI/UX 디자이너가 작성하여 전달.\n",
      "\n",
      "이상으로 ABC 기술 회사 제품 개발 팀 주간 진행 상황 회의 회의록을 마치겠습니다."
     ]
    }
   ],
   "source": [
    "# chain 생성\n",
    "chain = final_prompt | llm\n",
    "\n",
    "# 실행 및 결과 출력\n",
    "answer = chain.stream(question)\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.is_lc_serializable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'],\n",
       " 'kwargs': {'first': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'],\n",
       "   'kwargs': {'input_variables': ['input', 'instruction'],\n",
       "    'messages': [{'lc': 1,\n",
       "      'type': 'constructor',\n",
       "      'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'],\n",
       "      'kwargs': {'prompt': {'lc': 1,\n",
       "        'type': 'constructor',\n",
       "        'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "        'kwargs': {'input_variables': [],\n",
       "         'template': 'You are a helpful assistant.',\n",
       "         'template_format': 'f-string'},\n",
       "        'name': 'PromptTemplate',\n",
       "        'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "          {'id': 1,\n",
       "           'type': 'runnable',\n",
       "           'data': {'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "            'name': 'PromptTemplate'}},\n",
       "          {'id': 2, 'type': 'schema', 'data': 'PromptTemplateOutput'}],\n",
       "         'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}}}},\n",
       "     {'lc': 1,\n",
       "      'type': 'not_implemented',\n",
       "      'id': ['langchain_core',\n",
       "       'prompts',\n",
       "       'few_shot',\n",
       "       'FewShotChatMessagePromptTemplate'],\n",
       "      'repr': \"FewShotChatMessagePromptTemplate(example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000026C71261410>, k=1, example_keys=None, input_keys=None, vectorstore_kwargs=None), example_prompt=ChatPromptTemplate(input_variables=['answer', 'input', 'instruction'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'instruction'], template='{instruction}:\\\\n{input}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['answer'], template='{answer}'))]))\",\n",
       "      'name': 'FewShotChatMessagePromptTemplate',\n",
       "      'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "        {'id': 1,\n",
       "         'type': 'runnable',\n",
       "         'data': {'id': ['langchain',\n",
       "           'schema',\n",
       "           'prompt_template',\n",
       "           'FewShotChatMessagePromptTemplate'],\n",
       "          'name': 'FewShotChatMessagePromptTemplate'}},\n",
       "        {'id': 2,\n",
       "         'type': 'schema',\n",
       "         'data': 'FewShotChatMessagePromptTemplateOutput'}],\n",
       "       'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}},\n",
       "     {'lc': 1,\n",
       "      'type': 'constructor',\n",
       "      'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'],\n",
       "      'kwargs': {'prompt': {'lc': 1,\n",
       "        'type': 'constructor',\n",
       "        'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "        'kwargs': {'input_variables': ['input', 'instruction'],\n",
       "         'template': '{instruction}\\n{input}',\n",
       "         'template_format': 'f-string'},\n",
       "        'name': 'PromptTemplate',\n",
       "        'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "          {'id': 1,\n",
       "           'type': 'runnable',\n",
       "           'data': {'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "            'name': 'PromptTemplate'}},\n",
       "          {'id': 2, 'type': 'schema', 'data': 'PromptTemplateOutput'}],\n",
       "         'edges': [{'source': 0, 'target': 1},\n",
       "          {'source': 1, 'target': 2}]}}}}]},\n",
       "   'name': 'ChatPromptTemplate',\n",
       "   'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "     {'id': 1,\n",
       "      'type': 'runnable',\n",
       "      'data': {'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'],\n",
       "       'name': 'ChatPromptTemplate'}},\n",
       "     {'id': 2, 'type': 'schema', 'data': 'ChatPromptTemplateOutput'}],\n",
       "    'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}},\n",
       "  'last': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       "   'kwargs': {'model_name': 'gpt-3.5-turbo',\n",
       "    'temperature': 0.0,\n",
       "    'openai_api_key': {'lc': 1, 'type': 'secret', 'id': ['OPENAI_API_KEY']},\n",
       "    'openai_proxy': '',\n",
       "    'max_retries': 2,\n",
       "    'n': 1},\n",
       "   'name': 'ChatOpenAI',\n",
       "   'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'ChatOpenAIInput'},\n",
       "     {'id': 1,\n",
       "      'type': 'runnable',\n",
       "      'data': {'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       "       'name': 'ChatOpenAI'}},\n",
       "     {'id': 2, 'type': 'schema', 'data': 'ChatOpenAIOutput'}],\n",
       "    'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}}},\n",
       " 'name': 'RunnableSequence',\n",
       " 'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "   {'id': 1,\n",
       "    'type': 'runnable',\n",
       "    'data': {'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'],\n",
       "     'name': 'ChatPromptTemplate'}},\n",
       "   {'id': 2,\n",
       "    'type': 'runnable',\n",
       "    'data': {'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       "     'name': 'ChatOpenAI'}},\n",
       "   {'id': 3, 'type': 'schema', 'data': 'ChatOpenAIOutput'}],\n",
       "  'edges': [{'source': 0, 'target': 1},\n",
       "   {'source': 2, 'target': 3},\n",
       "   {'source': 1, 'target': 2}]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumpd\n",
    "\n",
    "dumped_chain = dumpd(chain)\n",
    "dumped_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# fuit_chain.pkl 파일로 직렬화된 체인을 저장합니다.\n",
    "with open(\"./summary_chain.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dumped_chain, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'],\n",
       " 'kwargs': {'first': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'],\n",
       "   'kwargs': {'input_variables': ['input', 'instruction'],\n",
       "    'messages': [{'lc': 1,\n",
       "      'type': 'constructor',\n",
       "      'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'],\n",
       "      'kwargs': {'prompt': {'lc': 1,\n",
       "        'type': 'constructor',\n",
       "        'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "        'kwargs': {'input_variables': [],\n",
       "         'template': 'You are a helpful assistant.',\n",
       "         'template_format': 'f-string'},\n",
       "        'name': 'PromptTemplate',\n",
       "        'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "          {'id': 1,\n",
       "           'type': 'runnable',\n",
       "           'data': {'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "            'name': 'PromptTemplate'}},\n",
       "          {'id': 2, 'type': 'schema', 'data': 'PromptTemplateOutput'}],\n",
       "         'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}}}},\n",
       "     {'lc': 1,\n",
       "      'type': 'not_implemented',\n",
       "      'id': ['langchain_core',\n",
       "       'prompts',\n",
       "       'few_shot',\n",
       "       'FewShotChatMessagePromptTemplate'],\n",
       "      'repr': \"FewShotChatMessagePromptTemplate(example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000026C71261410>, k=1, example_keys=None, input_keys=None, vectorstore_kwargs=None), example_prompt=ChatPromptTemplate(input_variables=['answer', 'input', 'instruction'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'instruction'], template='{instruction}:\\\\n{input}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['answer'], template='{answer}'))]))\",\n",
       "      'name': 'FewShotChatMessagePromptTemplate',\n",
       "      'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "        {'id': 1,\n",
       "         'type': 'runnable',\n",
       "         'data': {'id': ['langchain',\n",
       "           'schema',\n",
       "           'prompt_template',\n",
       "           'FewShotChatMessagePromptTemplate'],\n",
       "          'name': 'FewShotChatMessagePromptTemplate'}},\n",
       "        {'id': 2,\n",
       "         'type': 'schema',\n",
       "         'data': 'FewShotChatMessagePromptTemplateOutput'}],\n",
       "       'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}},\n",
       "     {'lc': 1,\n",
       "      'type': 'constructor',\n",
       "      'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'],\n",
       "      'kwargs': {'prompt': {'lc': 1,\n",
       "        'type': 'constructor',\n",
       "        'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "        'kwargs': {'input_variables': ['input', 'instruction'],\n",
       "         'template': '{instruction}\\n{input}',\n",
       "         'template_format': 'f-string'},\n",
       "        'name': 'PromptTemplate',\n",
       "        'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "          {'id': 1,\n",
       "           'type': 'runnable',\n",
       "           'data': {'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'],\n",
       "            'name': 'PromptTemplate'}},\n",
       "          {'id': 2, 'type': 'schema', 'data': 'PromptTemplateOutput'}],\n",
       "         'edges': [{'source': 0, 'target': 1},\n",
       "          {'source': 1, 'target': 2}]}}}}]},\n",
       "   'name': 'ChatPromptTemplate',\n",
       "   'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "     {'id': 1,\n",
       "      'type': 'runnable',\n",
       "      'data': {'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'],\n",
       "       'name': 'ChatPromptTemplate'}},\n",
       "     {'id': 2, 'type': 'schema', 'data': 'ChatPromptTemplateOutput'}],\n",
       "    'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}},\n",
       "  'last': {'lc': 1,\n",
       "   'type': 'constructor',\n",
       "   'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       "   'kwargs': {'model_name': 'gpt-3.5-turbo',\n",
       "    'temperature': 0.0,\n",
       "    'openai_api_key': {'lc': 1, 'type': 'secret', 'id': ['OPENAI_API_KEY']},\n",
       "    'openai_proxy': '',\n",
       "    'max_retries': 2,\n",
       "    'n': 1},\n",
       "   'name': 'ChatOpenAI',\n",
       "   'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'ChatOpenAIInput'},\n",
       "     {'id': 1,\n",
       "      'type': 'runnable',\n",
       "      'data': {'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       "       'name': 'ChatOpenAI'}},\n",
       "     {'id': 2, 'type': 'schema', 'data': 'ChatOpenAIOutput'}],\n",
       "    'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}]}}},\n",
       " 'name': 'RunnableSequence',\n",
       " 'graph': {'nodes': [{'id': 0, 'type': 'schema', 'data': 'PromptInput'},\n",
       "   {'id': 1,\n",
       "    'type': 'runnable',\n",
       "    'data': {'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'],\n",
       "     'name': 'ChatPromptTemplate'}},\n",
       "   {'id': 2,\n",
       "    'type': 'runnable',\n",
       "    'data': {'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       "     'name': 'ChatOpenAI'}},\n",
       "   {'id': 3, 'type': 'schema', 'data': 'ChatOpenAIOutput'}],\n",
       "  'edges': [{'source': 0, 'target': 1},\n",
       "   {'source': 2, 'target': 3},\n",
       "   {'source': 1, 'target': 2}]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./summary_chain.pkl\", \"rb\") as f:\n",
    "    loaded_chain = pickle.load(f)\n",
    "\n",
    "loaded_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'suffix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_prompt\n\u001b[1;32m----> 3\u001b[0m loaded_chain \u001b[38;5;241m=\u001b[39m \u001b[43mload_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_chain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kim_h\\anaconda3\\envs\\rag\\Lib\\site-packages\\langchain_core\\prompts\\loading.py:138\u001b[0m, in \u001b[0;36mload_prompt\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlc://\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading from the deprecated github-based Hub is no longer supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use the new LangChain Hub at https://smith.langchain.com/hub \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m     )\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_prompt_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kim_h\\anaconda3\\envs\\rag\\Lib\\site-packages\\langchain_core\\prompts\\loading.py:151\u001b[0m, in \u001b[0;36m_load_prompt_from_file\u001b[1;34m(file, encoding)\u001b[0m\n\u001b[0;32m    149\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m file\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Load from either json or yaml.\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffix\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, encoding\u001b[38;5;241m=\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    153\u001b[0m         config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'suffix'"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "# from langchain.load.load import load\n",
    "\n",
    "loaded_chain = load_prompt(loaded_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이거 어떻게 해결하냐..?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
