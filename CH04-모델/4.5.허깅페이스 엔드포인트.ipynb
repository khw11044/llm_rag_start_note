{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 허깅페이스 엔드포인트(HuggingFace Endpoints)\n",
    "\n",
    "__Huggingface Endpoints__\n",
    "\n",
    "Hugging Face Hub은 12만 개 이상의 모델, 2만 개의 데이터셋, 5만 개의 데모 앱(Spaces)을 보유한 플랫폼으로, 모두 오픈 소스이며 공개적으로 사용 가능합니다. 이 온라인 플랫폼에서 사람들은 쉽게 협업하고 함께 머신러닝을 구축할 수 있습니다.\n",
    "\n",
    "Hugging Face Hub은 또한 다양한 ML 애플리케이션을 구축하기 위한 다양한 엔드포인트를 제공합니다. 이 예제는 다양한 유형의 엔드포인트에 연결하는 방법을 보여줍니다.\n",
    "\n",
    "특히, 텍스트 생성 추론은 Text Generation Inference에 의해 구동됩니다. 이는 매우 빠른 텍스트 생성 추론을 위해 맞춤 제작된 Rust, Python, gRPC 서버입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 허깅페이스 토큰 발급\n",
    "허깅페이스(https://huggingface.co) 에 회원가입을 한 뒤, 아래의 주소에서 토큰 발급을 신청합니다.\n",
    "\n",
    "토큰 발급주소: https://huggingface.co/docs/hub/security-tokens\n",
    "\n",
    "발급받은 토큰을 .env 파일에 HUGGINGFACEHUB_API_TOKEN = 로 지정하거나 \n",
    "\n",
    "```python \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace 모델 리스트\n",
    "\n",
    "- 허깅페이스 LLM 리더보드: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n",
    "- 모델 리스트: https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation and Setup\n",
    "\n",
    "HuggingFaceEndpoint 클래스를 사용하여 Hugging Face 엔드포인트와 상호 작용할 수 있습니다.\n",
    "\n",
    "- langchain_community.llms 모듈에서 HuggingFaceEndpoint 클래스를 임포트합니다.\n",
    "- HuggingFaceEndpoint 클래스를 사용하면 Hugging Face에서 호스팅되는 언어 모델과 통신할 수 있습니다.\n",
    "- 이 클래스는 Hugging Face 엔드포인트의 URL과 필요한 인증 정보를 사용하여 초기화됩니다.\n",
    "- 초기화된 HuggingFaceEndpoint 객체를 통해 프롬프트를 전송하고 언어 모델의 응답을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a720e2fbe8644017a386d16d447a8d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf_zw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# # 이거 꼭 해야함\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "print(HUGGINGFACEHUB_API_TOKEN[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Examples\n",
    "\n",
    "예시 데이터를 준비하는 과정입니다.\n",
    "\n",
    "HuggingFaceEndpoint 클래스를 사용하여 Hugging Face 엔드포인트와 상호 작용할 수 있습니다.\n",
    "\n",
    "- langchain_community.llms 모듈에서 HuggingFaceEndpoint 클래스를 임포트합니다.\n",
    "- HuggingFaceEndpoint 클래스를 사용하면 Hugging Face에서 호스팅되는 언어 모델과 통신할 수 있습니다.\n",
    "- 이 클래스는 Hugging Face 엔드포인트의 URL과 필요한 인증 정보를 사용하여 초기화됩니다.\n",
    "- 초기화된 HuggingFaceEndpoint 객체를 통해 프롬프트를 전송하고 언어 모델의 응답을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- question 변수에 \"1994년 FIFA 월드컵에서 우승한 팀은 어디인가요?\"라는 질문을 할당합니다.\n",
    "- template 변수에 질문과 답변 형식을 지정하는 템플릿 문자열을 할당합니다.\n",
    "- 템플릿에는 {question} 플레이스홀더가 포함되어 있습니다.\n",
    "- 답변 부분에는 \"단계별로 생각해 보겠습니다.\"라는 문구가 포함되어 있습니다.\n",
    "- PromptTemplate.from_template() 메서드를 사용하여 template을 기반으로 PromptTemplate 객체인 prompt를 생성합니다.\n",
    "- 이를 통해 질문을 템플릿에 삽입하여 프롬프트를 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Please answer the following questions concisely.\n",
    "QUESTION: {question}\n",
    "\n",
    "ANSWER: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "다음은 무료 [Serverless Endpoints](https://huggingface.co/docs/api-inference/index) API의 HuggingFaceEndpoint 통합에 액세스하는 방법의 예시입니다.\n",
    "\n",
    "- repo_id 변수에 \"mistralai/Mistral-7B-Instruct-v0.2\" 모델의 저장소 ID를 할당합니다.\n",
    "- HuggingFaceEndpoint를 사용하여 llm 객체를 생성합니다.\n",
    "- repo_id로 지정된 모델을 사용합니다.\n",
    "- max_length를 128로 설정하여 생성할 최대 토큰 수를 제한합니다.\n",
    "- temperature를 0.5로 설정하여 생성 결과의 다양성을 조절합니다.\n",
    "- token에 HUGGINGFACEHUB_API_TOKEN을 전달하여 인증합니다.\n",
    "- LLMChain을 사용하여 llm_chain 객체를 생성합니다.\n",
    "- prompt 변수에 할당된 프롬프트를 사용합니다.\n",
    "- llm 매개변수에 이전에 생성한 llm 객체를 전달합니다.\n",
    "- llm_chain.run(question)을 호출하여 주어진 질문에 대한 답변을 생성합니다.\n",
    "- 생성된 답변을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kim_h\\anaconda3\\envs\\rag\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\kim_h\\anaconda3\\envs\\rag\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\kim_h\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "1. Gyeongbokgung Palace: This is the largest of the Five Grand Palaces built by the Joseon dynasty. It's a must-visit for its historical significance and beautiful architecture.\n",
      "\n",
      "2. Myeongdong: This is a shopping district that's famous for its cosmetic shops, street food, and fashion boutiques. It's a great place to experience the local culture and try some delicious Korean snacks.\n",
      "\n",
      "3. Bukchon Hanok Village: This traditional Korean village is home to hundreds of hanok houses, which are traditional Korean homes. It's a great place to take a stroll and soak in the traditional Korean atmosphere.\n",
      "\n",
      "4. N Seoul Tower: Also known as Namsan Tower, this is a communication and observation tower located on Namsan Mountain in central Seoul. It offers panoramic views of the city and is a popular spot for couples to lock \"love padlocks\" to the fence as a symbol of their love.\n",
      "\n",
      "5. Insadong: This is a great place to experience traditional Korean culture. It's home to many antique shops, tea houses, and traditional Korean restaurants. Don't"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 사용할 모델의 저장소 ID를 설정합니다.\n",
    "# repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "# repo_id = \"google/gemma-7b\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,  # 모델 저장소 ID를 지정합니다.\n",
    "    max_new_tokens=256,  # 생성할 최대 토큰 길이를 설정합니다.\n",
    "    temperature=0.1,  # 샘플링 온도를 설정합니다. 값이 높을수록 더 다양한 출력을 생성합니다.\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],  # 콜백을 설정합니다.\n",
    "    streaming=True,  # 스트리밍을 사용합니다.\n",
    ")\n",
    "\n",
    "# LLMChain을 초기화하고 프롬프트와 언어 모델을 전달합니다.\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\n",
    "response = llm_chain.invoke(\n",
    "    {\"question\": \"Please tell me top 5 places to visit in Seoul, Korea.\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Please tell me top 5 places to visit in Seoul, Korea.', 'text': '1. Gyeongbokgung Palace: This is the largest of the Five Grand Palaces built by the Joseon dynasty. It\\'s a must-visit for its historical significance and beautiful architecture.\\n\\n2. Myeongdong: This is a shopping district that\\'s famous for its cosmetic shops, street food, and fashion boutiques. It\\'s a great place to experience the local culture and try some delicious Korean snacks.\\n\\n3. Bukchon Hanok Village: This traditional Korean village is home to hundreds of hanok houses, which are traditional Korean homes. It\\'s a great place to take a stroll and soak in the traditional Korean atmosphere.\\n\\n4. N Seoul Tower: Also known as Namsan Tower, this is a communication and observation tower located on Namsan Mountain in central Seoul. It offers panoramic views of the city and is a popular spot for couples to lock \"love padlocks\" to the fence as a symbol of their love.\\n\\n5. Insadong: This is a great place to experience traditional Korean culture. It\\'s home to many antique shops, tea houses, and traditional Korean restaurants. Don\\'t'}\n"
     ]
    }
   ],
   "source": [
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\kim_h\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "안녕하세요! 대한민국 서울에 방문하시면 꼭 가야 할 관광지 5곳을 소개해드리겠습니다.\n",
      "1. 광화문 옥상 : 서울의 대표적인 관광지 중 하나로, 옥상에서  BUSAN 시내를 감상할 수 있어요.\n",
      "2. 경복궁 : 조선 왕조 시절의 역사와 문화를 느낄 수 있는 곳입니다.\n",
      "3. 명동 : 서울의 문화와 역사가 살아 숨쉬는 곳으로, 맛집과 쇼핑도 즐길 수 있어요.\n",
      "4. 서울타워 : 밤에 가보면 아름"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"존댓말로 답변해주세요. 답변에 대한 이유를 간결하게 답변해주세요. 다음과 같은 형식으로 대답해주세요.\n",
    "QUESTION: {question}\n",
    "\n",
    "ANSWER: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,  # 모델 저장소 ID를 지정합니다.\n",
    "    max_new_tokens=256,  # 생성할 최대 토큰 길이를 설정합니다.\n",
    "    top_k=10,           # 상위 K개의 토큰을 선택합니다.\n",
    "    top_p=0.95,         # 누적 확률이 top_p에 도달할 때까지 토큰을 선택합니다.\n",
    "    typical_p=0.95,     # typical_p 확률 이상의 토큰만 선택합니다.\n",
    "    temperature=0.01,  # 샘플링 온도를 설정합니다. 값이 높을수록 더 다양한 출력을 생성합니다.\n",
    "    repetition_penalty=1.03, # 반복 패널티를 설정합니다. 높을수록 반복을 줄입니다.\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],  # 콜백을 설정합니다.\n",
    "    streaming=True,  # 스트리밍을 사용합니다.\n",
    ")\n",
    "\n",
    "# LLMChain을 초기화하고 프롬프트와 언어 모델을 전달합니다.\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\n",
    "response = llm_chain.invoke(\n",
    "    {\"question\": \"대한민국 서울에 방문할 때 꼭 가야할 관광지 5곳을 알려줘.\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
